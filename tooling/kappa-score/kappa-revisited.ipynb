{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kappa score calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# Project variables\n",
    "inputFile = \"input.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import CSV\n",
    "Import the CSV and drop collums that are not relevant for this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       Marten     Rick                                    Krishan\n0      not-ak   not-ak                                     not-ak\n1  technology   not-ak  technology,existence,existence-behavioral\n2  technology   not-ak  technology,existence,existence-behavioral\n3      not-ak   not-ak                                     not-ak\n4     process  process                                    process",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Marten</th>\n      <th>Rick</th>\n      <th>Krishan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>not-ak</td>\n      <td>not-ak</td>\n      <td>not-ak</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>technology</td>\n      <td>not-ak</td>\n      <td>technology,existence,existence-behavioral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>technology</td>\n      <td>not-ak</td>\n      <td>technology,existence,existence-behavioral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>not-ak</td>\n      <td>not-ak</td>\n      <td>not-ak</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>process</td>\n      <td>process</td>\n      <td>process</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(inputFile)\n",
    "\n",
    "# Drop the index, thread and email ID\n",
    "data.drop(\"#\", inplace=True, axis=1)\n",
    "data.drop(\"Tread Id\", inplace=True, axis=1)\n",
    "data.drop(\"Email ID\", inplace=True, axis=1)\n",
    "data.drop(\"Agreement?\", inplace=True, axis=1)\n",
    "data.drop(\"Decided\", inplace=True, axis=1)\n",
    "\n",
    "# Drop NaN value rows\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Display\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not-ak\n",
      "technology\n",
      "process\n",
      "existence\n",
      "existence-structural\n",
      "existence-behavioral\n",
      "property\n",
      "existence-behaviour\n"
     ]
    }
   ],
   "source": [
    "# Get unique labels used in the input set.\n",
    "# Used to verify validate validity of the data.\n",
    "uniques = pd.unique(data.values.ravel(\"K\"))\n",
    "uniques = pd.Series(uniques).map(lambda x: x.split(',')).explode().unique()\n",
    "\n",
    "# Display unqiues\n",
    "for label in uniques:\n",
    "    print(label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert to AK and Not-AK\n",
    "Used for comparisons of Kappa score for checking if the group is on the same line for this property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Marten       Rick    Krishan\n",
      "0       not-ak     not-ak     not-ak\n",
      "1    executive     not-ak  executive\n",
      "2    executive     not-ak  executive\n",
      "3       not-ak     not-ak     not-ak\n",
      "4    executive  executive  executive\n",
      "..         ...        ...        ...\n",
      "99   existence  existence  existence\n",
      "100     not-ak     not-ak     not-ak\n",
      "101  existence  existence  existence\n",
      "102     not-ak     not-ak     not-ak\n",
      "103     not-ak     not-ak     not-ak\n",
      "\n",
      "[99 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Hierachy for most important to least important labels\n",
    "labelHierachy = [\"technology\", \"process\", \"property\", \"existence\", \"not-ak\"]\n",
    "\n",
    "def f(row):\n",
    "    # This can be nicer in one loop probably (or with a 3 one-liners) but I dont really care tbh.\n",
    "    for label in labelHierachy:\n",
    "        if label in row[0]:\n",
    "            row[0] = label\n",
    "            if label == \"technology\" or label == \"process\":\n",
    "                row[0] = \"executive\"\n",
    "            break\n",
    "    for label in labelHierachy:\n",
    "        if label in row[1]:\n",
    "            row[1] = label\n",
    "            if label == \"technology\" or label == \"process\":\n",
    "                row[1] = \"executive\"\n",
    "            break\n",
    "    for label in labelHierachy:\n",
    "        if label in row[2]:\n",
    "            row[2] = label\n",
    "            if label == \"technology\" or label == \"process\":\n",
    "                row[2] = \"executive\"\n",
    "            break\n",
    "    return row\n",
    "\n",
    "copy = data.copy()\n",
    "\n",
    "copy.apply(f, axis=1)\n",
    "print(copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Created from rows 0 till 50\n",
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} &    Marten &      Rick &   Krishan \\\\\n",
      "\\midrule\n",
      "Marten  &       1.0 &  0.469112 &    0.6557 \\\\\n",
      "Rick    &  0.469112 &       1.0 &  0.490229 \\\\\n",
      "Krishan &    0.6557 &  0.490229 &       1.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "--------------------------------------------\n",
      "Created from rows 51 till 103\n",
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} &    Marten &      Rick &   Krishan \\\\\n",
      "\\midrule\n",
      "Marten  &       1.0 &  0.528796 &  0.425757 \\\\\n",
      "Rick    &  0.528796 &       1.0 &  0.415426 \\\\\n",
      "Krishan &  0.425757 &  0.415426 &       1.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rickt\\AppData\\Local\\Temp\\ipykernel_25380\\1619945138.py:19: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(output.to_latex())\n",
      "C:\\Users\\rickt\\AppData\\Local\\Temp\\ipykernel_25380\\1619945138.py:19: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(output.to_latex())\n"
     ]
    }
   ],
   "source": [
    "def calculateKappa(df, start=0, end=None):\n",
    "    if end == None:\n",
    "        end = df.shape[0]\n",
    "\n",
    "    colLength = df.shape[1]\n",
    "    output = pd.DataFrame(columns=df.columns, index=df.columns)\n",
    "\n",
    "    output\n",
    "\n",
    "    for rIdx in range(0, colLength):\n",
    "        part1 = df.iloc[start:end, rIdx]\n",
    "        for cIdx in range(0, colLength):\n",
    "            part2 = df.iloc[start:end, cIdx]\n",
    "            output.iloc[cIdx, rIdx] = cohen_kappa_score(part1, part2)\n",
    "\n",
    "    # Print the output\n",
    "    print(\"--------------------------------------------\")\n",
    "    print(f\"Created from rows {start} till {end}\")\n",
    "    print(output.to_latex())\n",
    "\n",
    "calculateKappa(copy, end=50)\n",
    "calculateKappa(copy, start=51, end = 103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f96857dcf09c01b022c7fccf7a442c6a45ebb3edc34ea79c7bc0ebc6fd42b24a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
